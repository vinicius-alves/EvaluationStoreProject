{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Core.DTO import *\n",
    "from Core.Relations import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConexÃ£o com banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ ConfiguraÃ§Ã£o do banco (pode ser reutilizada para qualquer ModelDTOo)\n",
    "mongo_url = \"mongodb://localhost:27017/\"\n",
    "db_manager = DatabaseManager('mysql+pymysql://root:000000000@localhost/mydb', mongo_url = mongo_url)\n",
    "session = db_manager.get_session()\n",
    "dataset_repo = DatasetRepository(session)\n",
    "conversor = ConverterDTO(session=session)\n",
    "mongo_db = db_manager.get_mongo_db()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'LoanDefaultPrediction'\n",
    "target_feature_name = 'default'\n",
    "name_space= project_name\n",
    "\n",
    "\n",
    "def process_raw_loan_data():\n",
    "\n",
    "    columns = ['id', 'loan_amnt', 'term', 'int_rate', 'installment', 'emp_length',\n",
    "       'home_ownership', 'annual_inc', 'verification_status', 'issue_d',\n",
    "       'loan_status', 'purpose', 'addr_state', 'dti']\n",
    "\n",
    "    df = pd.read_csv('data//Loan.csv', usecols = columns )\n",
    "    \n",
    "    df['term'] = df['term'].str.strip().str.split(' ').map(lambda x: x[0]) \n",
    "    df['timestamp'] = pd.to_datetime(df['issue_d'], format=\"%b-%y\")\n",
    "\n",
    "    dict_emp = {'10+ years': 10,\n",
    "    '< 1 year': 0,\n",
    "    '1 year': 1,\n",
    "    '3 years': 3,\n",
    "    '8 years': 8,\n",
    "    '9 years': 9,\n",
    "    '4 years': 4,\n",
    "    '5 years': 5,\n",
    "    '6 years': 6,\n",
    "    '2 years': 2,\n",
    "    '7 years': 7}\n",
    "\n",
    "    ix = df['emp_length'].notnull()\n",
    "    df.loc[ix,'emp_length'] = df.loc[ix,'emp_length'].map(lambda x : dict_emp[x])\n",
    "    df['emp_length'] = df['emp_length'].astype('float')\n",
    "    df['int_rate'] = df['int_rate'].str.replace('%','', regex=False).astype('float')\n",
    "\n",
    "    df = df[df['loan_status'] != 'Current'].reset_index(drop=True)\n",
    "    df['default'] = (df['loan_status'] == 'Charged Off').astype('int')\n",
    "    df.drop(columns = ['issue_d','loan_status'], inplace=True)\n",
    "    df.rename(columns={'id':'idEntity'}, inplace=True)\n",
    "\n",
    "    df_melt = df.melt(id_vars = ['timestamp','idEntity'], value_vars = df.drop(columns = 'timestamp').columns)\n",
    "    df_melt['type'] = df_melt['value'].map(lambda x : type(x).__name__)\n",
    "    df_melt.rename(columns ={'variable':'name'}, inplace=True)\n",
    "\n",
    "    return df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = Dataset(name = project_name)\n",
    "item_exists, dataset_dto = conversor.get_if_exists(dataset)\n",
    "\n",
    "if not(item_exists):\n",
    "    df = process_raw_loan_data()\n",
    "\n",
    "    dataset_dto = DatasetDTO(name = project_name ) \n",
    "    lst_features= df['name'].drop_duplicates().to_list()\n",
    "    dataset_dto.process_feature_list(lst_features= lst_features, name_space=name_space)\n",
    "    dataset_repo.save(dataset_dto)\n",
    "    item_exists, dataset_dto = conversor.get_if_exists(dataset)\n",
    "    dataset_dto.save_data_mongo(mongo_db ,df = df)\n",
    "\n",
    "dataset_dto.load_data_from_mongo(mongo_db)\n",
    "dataset = dataset_dto.dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetFeature = Feature(name = target_feature_name, nameSpace = FeatureNameSpace(name = name_space))\n",
    "project = Project(name  = project_name, projectType = ProjectType(name = 'Classification'), targetFeature = targetFeature)\n",
    "\n",
    "item_exists,project_dto = conversor.get_if_exists(project)\n",
    "\n",
    "if not(item_exists):\n",
    "\ttargetFeature = dataset_dto.get_feature_by_name(name = target_feature_name)\n",
    "\tproject_dto =ProjectDTO(name  = project_name, projectType = ProjectTypeDTO(name = 'Classification'), targetFeature = targetFeature)\n",
    "\tProjectRepository(session=session).save(project_dto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3c475988f049178fc41f78483b4722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|===================| 711/712 [00:12<00:00]        c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "datas = pd.date_range(start=\"2009-01-01\", end=\"2011-11-01\", freq=\"MS\")\n",
    "for data_inicio in tqdm(datas):\n",
    "    data_fim = pd.date_range(start=data_inicio, periods=1, freq=\"ME\")[0]\n",
    "\n",
    "    #treinando\n",
    "    model = OHERandomForestClassifier()\n",
    "    task = ClassificationTrainingTask (dataset = dataset) \n",
    "    run = Run(project = project, task = task,  model = model)\n",
    "    run.execute( task_parameters={'end_date':data_inicio})\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)   \n",
    "    run_repo.save(run_dto)\n",
    "\n",
    "    #prediÃ§Ã£o\n",
    "    model.idModel =  run_dto.model.idModel\n",
    "    task = ClassificationPredictionTask (dataset = dataset) \n",
    "    run = Run(project = project, task = task,  model = model)\n",
    "    run.execute( task_parameters={'start_date':data_inicio,'end_date':data_fim})\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)\n",
    "    run_repo.save(run_dto)\n",
    "\n",
    "    #drift features\n",
    "    task = FeatureDriftCheckTask (dataset = dataset) \n",
    "    run = Run(project = project, task = task,  model = None)\n",
    "    run.execute( task_parameters={'end_reference_date':data_inicio,\n",
    "                                  'start_current_date':data_inicio,'end_current_date':data_fim})\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)\n",
    "    run_repo.save(run_dto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seoul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'SeoulBike'\n",
    "target_feature_name = 'rented_bike_count'\n",
    "name_space= project_name\n",
    "\n",
    "def process_raw_seoul_data():\n",
    "\n",
    "    def remove_parentheses_content(text):\n",
    "        return re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "    df = pd.read_csv('data//SeoulBikeData.csv', encoding='latin1')\n",
    "    df.columns = [remove_parentheses_content(i.lower()).strip().replace(' ','_') for i in df.columns]\n",
    "    df['timestamp'] = df['date'].map(lambda x : datetime.strptime(x,  \"%d/%m/%Y\"))\n",
    "    df = df.drop(columns = 'date')\n",
    "    df['timestamp'] = df['timestamp'] + pd.to_timedelta(df['hour'], unit='h')\n",
    "    df_melt = df.melt(id_vars = ['timestamp'], value_vars = df.drop(columns = 'timestamp').columns)\n",
    "    df_melt['idEntity'] = '1'\n",
    "    df_melt['type'] = df_melt['value'].map(lambda x : type(x).__name__)\n",
    "    df_melt.rename(columns ={'variable':'name'}, inplace=True)\n",
    "    return df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = Dataset(name = project_name)\n",
    "item_exists, dataset_dto = conversor.get_if_exists(dataset)\n",
    "\n",
    "if not(item_exists):\n",
    "    df = process_raw_seoul_data()\n",
    "\n",
    "    dataset_dto = DatasetDTO(name = project_name ) \n",
    "    lst_features= df['name'].drop_duplicates().to_list()\n",
    "    dataset_dto.process_feature_list(lst_features= lst_features, name_space=name_space)\n",
    "    dataset_repo.save(dataset_dto)\n",
    "    item_exists, dataset_dto = conversor.get_if_exists(dataset)\n",
    "    dataset_dto.save_data_mongo(mongo_db ,df = df)\n",
    "\n",
    "dataset_dto.load_data_from_mongo(mongo_db)\n",
    "dataset = dataset_dto.dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetFeature = Feature(name = target_feature_name, nameSpace = FeatureNameSpace(name = name_space))\n",
    "project = Project(name  = project_name, projectType = ProjectType(name = 'Regression'), targetFeature = targetFeature)\n",
    "\n",
    "item_exists,project_dto = conversor.get_if_exists(project)\n",
    "\n",
    "if not(item_exists):\n",
    "\ttargetFeature = dataset_dto.get_feature_by_name(name = target_feature_name)\n",
    "\tproject_dto =ProjectDTO(name  = project_name, projectType = ProjectTypeDTO(name = 'Regression'), targetFeature = targetFeature)\n",
    "\tProjectRepository(session=session).save(project_dto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e313e45255524e518800c6457e8eff00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datas = pd.date_range(start=\"2018-01-01\", end=\"2018-11-30\", freq=\"MS\")  \n",
    "for data_inicio in tqdm(datas):\n",
    "    data_fim = pd.date_range(start=data_inicio, periods=1, freq=\"ME\")[0]\n",
    "\n",
    "    #treinando\n",
    "    model = OHEDecisionTreeRegressor()\n",
    "    task = RegressionPredictionTask (dataset = dataset) \n",
    "    run = Run(project = project, task = task,  model = model)\n",
    "    run.execute( task_parameters={'end_date':data_inicio})\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)   \n",
    "    run_repo.save(run_dto)\n",
    "\n",
    "    #prediÃ§Ã£o\n",
    "    model.idModel =  run_dto.model.idModel\n",
    "    task = RegressionPredictionTask (dataset = dataset) \n",
    "    run = Run(project = project, task = task,  model = model)\n",
    "    run.execute( task_parameters={'start_date':data_inicio,'end_date':data_fim})\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)\n",
    "    run_repo.save(run_dto)\n",
    "\n",
    "    #drift features\n",
    "    task = FeatureDriftCheckTask (dataset = dataset) \n",
    "    run = Run(project = project, task = task,  model = None)\n",
    "    run.execute( task_parameters={'end_reference_date':data_inicio,\n",
    "                                  'start_current_date':data_inicio,'end_current_date':data_fim})\n",
    "    run_dto = conversor.converter_object_to_dto(run)\n",
    "    run_repo = RunRepository(session=session)\n",
    "    run_repo.save(run_dto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
